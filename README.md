# DeepRubin-Explorer ðŸŒŒ
### Real-time Transient Classification & Astrobiological Target Selection

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Data: ALeRCE Broker](https://img.shields.io/badge/Data-ALeRCE%20Broker-orange)](https://alerce.online/)

## ðŸ”­ Overview
This repository implements a Machine Learning pipeline designed for the **Vera C. Rubin Observatory's LSST** era. The goal is to move beyond static batch processing by implementing real-time classification of astronomical transients (SNe, AGNs, Variables) using streaming data from the **ALeRCE broker**.

Inspired by recent research in multiscale astrobiology (e.g., Ä†iprijanoviÄ‡ et al.), this project explores how high-cadence photometry can be used to identify anomalous signals that may warrant follow-up observations.

## ðŸ“¡ Scientific Motivation
How do we find life in a haystack of 10 million alerts per night? The **Vera C. Rubin Observatory (LSST)** will revolutionize our understanding of the dynamic universe, but its true power for astrobiology lies in **Anomaly Detection**. 

This project implements a high-performance Machine Learning pipeline to classify known astronomical transients (Supernovae, Variable Stars, AGNs). By mastering the "Expected Universe," we enable the identification of the **"Unexpected"**:
1. **Technosignature Candidates:** Signals that deviate from known physical models.
2. **Galactic Habitability:** Mapping high-energy events (SNe) that influence the chemical enrichment and sterilization risks of planetary systems.
3. **Interstellar Objects:** Identifying non-periodic transients that could be interstellar scouts or anomalous bolides.

## ðŸ§  ML Engineering Challenges
Transitioning from industrial ML to Astrophysics requires addressing domain-specific constraints:
* **Irregular Sampling:** Handling non-equidistant time series (cadence-dependent data).
* **Heteroscedastic Noise:** Integrating measurement uncertainties ($\sigma$) directly into the loss function.
* **Domain Shift:** Training on synthetic data (ELAsTiCC) and deploying on real survey streams (ZTF/Rubin).

## ðŸ› ï¸ Architecture
The project is structured following clean code principles for scientific reproducibility:
* `ingestion/`: API wrappers for ALeRCE and ZTF alert streams.
* `preprocessing/`: Gaussian Process (GP) interpolation and feature extraction.
* `models/`: PyTorch implementations of Time-Series Transformers and RNNs.
* `notebooks/`: Exploratory Data Analysis (EDA) and astrophysical validation.

## ðŸ“Š Data Source
Currently utilizing the **Zwicky Transient Facility (ZTF)** alert stream via the **ALeRCE Client**, serving as a high-fidelity precursor to the upcoming LSST data release.

## ðŸ“ˆ Roadmap
- [x] Data ingestion pipeline via ALeRCE API.
- [ ] Exploratory Data Analysis of SN Ia vs. SN II light curves.
- [ ] Implementation of a Deep Learning classifier (Temporal Convolutional Networks).
- [ ] Uncertainty estimation using Bayesian Neural Networks.

---

## ï¿½ Seguimiento de Experimentos con MLflow

### Â¿QuÃ© es MLflow?
Este proyecto utiliza **MLflow** como sistema de tracking de experimentos. MLflow registra automÃ¡ticamente cada ejecuciÃ³n de entrenamiento, incluyendo:
- **HiperparÃ¡metros:** Learning rate, batch size, nÃºmero de Ã©pocas, arquitectura del modelo.
- **MÃ©tricas de rendimiento:** Accuracy y Loss (entrenamiento y validaciÃ³n) registradas por Ã©poca.
- **Artefactos:** Versiones guardadas de los modelos entrenados (.pth) y datasets utilizados.
- **Metadata del dataset:** Rutas de archivos, nÃºmero de muestras, distribuciÃ³n de clases.

Esta funcionalidad permite comparar diferentes configuraciones, reproducir experimentos y auditar quÃ© versiÃ³n de datos generÃ³ cada modelo.

### CÃ³mo lanzar la interfaz de MLflow
DespuÃ©s de ejecutar el script de entrenamiento (`src/train.py`), lanza la interfaz web de MLflow desde la raÃ­z del proyecto:

```bash
mlflow ui
```

### CÃ³mo visualizar los experimentos
Abre tu navegador y accede a:

```
http://127.0.0.1:5000
```

### QuÃ© encontrarÃ¡s en la interfaz
- **Runs:** Lista de todas las ejecuciones de entrenamiento con sus parÃ¡metros e IDs Ãºnicos.
- **ComparaciÃ³n de experimentos:** VisualizaciÃ³n side-by-side de mÃ©tricas (Loss/Accuracy) entre diferentes corridas.
- **GrÃ¡ficos de evoluciÃ³n:** Trazado automÃ¡tico de la curva de aprendizaje (train_loss, val_loss, val_acc vs. epoch).
- **Artifacts:** Descarga directa del modelo entrenado (.pth) y del modelo completo serializado con PyTorch.
- **Data:** InformaciÃ³n del dataset utilizado en cada run, incluyendo rutas y estadÃ­sticas.

---

## ï¿½ðŸ“ˆ Data Visualization

The project currently explores real-time astronomical transients. Below is an example of a **Type Ia Supernova (SNIa)** light curve (Object: **ZTF18adoojej**) retrieved from the ALeRCE broker. 

![Light Curve Sample](assets/light_curve_sample.png)

> **Scientific Note:** Notice the irregular gaps between observations and the characteristic brightness decay. These gaps represent the "missing data challenge" that we aim to solve using Gaussian Processes, as suggested by modern astrophysical deep learning research.

---
**Author:** Giuliana Barbieri â€” *ML Engineer exploring the intersection of Big Data and Extragalactic Astrophysics.* 



