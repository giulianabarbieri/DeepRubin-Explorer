import os
import pandas as pd
from alerce.core import Alerce

class DataIngestor:
    """
    Handles data acquisition from the ALeRCE broker API.
    Facilitates the download of light curves for transient classification.
    """
    
    def __init__(self, output_dir="data"):
        self.client = Alerce()
        self.output_dir = output_dir
        
        # Ensure the data directory exists
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

    def fetch_sample_targets(self, class_name, count=50):
            """
            Retrieves a list of objects based on their astronomical classification.
            """
            print(f"[*] Fetching {count} targets for class: {class_name}...")
            
            targets = self.client.query_objects(
                classifier="lc_classifier",
                class_name=class_name,
                probability=0.85,
                page_size=count,
                format="pandas"
            )
            
            # DEBUG: Let's see what the API actually returned
            # print(f"DEBUG: Columns received: {targets.columns.tolist()}")

            # ALeRCE sometimes uses 'oid' (Object ID) or 'aid' (ALeRCE ID)
            # We ensure we have a column named 'oid' for the rest of the script
            if 'oid' not in targets.columns:
                if 'aid' in targets.columns:
                    targets = targets.rename(columns={'aid': 'oid'})
                else:
                    # If it's in the index, move it to a column
                    targets = targets.reset_index()
                    # If after reset it's called 'index' or 'aid', rename it
                    if 'oid' not in targets.columns:
                        targets.rename(columns={targets.columns[0]: 'oid'}, inplace=True)
                
            return targets

    def download_and_save(self, oid):
        """
        Downloads full light curve detections for a specific Object ID (OID).
        Saves the resulting dataframe to a CSV file.
        """
        try:
            # Query detections (flux vs time)
            detections = self.client.query_detections(oid, format="pandas")
            
            # Save to disk for local processing
            file_path = os.path.join(self.output_dir, f"{oid}_detections.csv")
            detections.to_csv(file_path, index=False)
            return True
        except Exception as e:
            print(f"[!] Error downloading {oid}: {e}")
            return False

if __name__ == "__main__":
    # Quick start: Download 10 Supernovae Type Ia
    ingestor = DataIngestor()
    sn_targets = ingestor.fetch_sample_targets("SNIa", count=10)
    
    for oid in sn_targets['oid']:
        success = ingestor.download_and_save(oid)
        if success:
            print(f"[+] Downloaded: {oid}")